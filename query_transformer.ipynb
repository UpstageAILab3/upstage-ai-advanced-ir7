{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Transformer with Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/myvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:13<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"rtzr/ko-gemma-2-9b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"rtzr/ko-gemma-2-9b-it\",\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_search_query(queries):\n",
    "    message = \"\"\"\n",
    "    ## Instructions\n",
    "    - 당신은 사용자의 여러 대화 메시지를 하나의 검색 쿼리로 변환하는 전문가입니다.\n",
    "    - 아래 사용자의 대화에서 중요한 정보만 추출하여 간결하고 명확한 검색용 쿼리로 변환하세요.\n",
    "    - 대화 형식이 아닌, 연구나 조사를 위한 검색어처럼 정확한 질문을 생성하세요.\n",
    "\n",
    "    ## 대화\n",
    "    \"\"\"\n",
    "\n",
    "    dialogue = [query['content'] for query in queries if query['role'] == 'user']\n",
    "\n",
    "    prompt = [{\"role\": \"user\", \"content\": message + '\\n'.join(dialogue)}]\n",
    "\n",
    "    chat_prompt = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(chat_prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(**inputs, max_new_tokens=200).to(device)\n",
    "    \n",
    "    search_query = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"-\" * 100)\n",
    "    print(chat_prompt)\n",
    "\n",
    "    result = [sent for sent in search_query.split('\\n') if sent != '']\n",
    "    return result[-1].strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = [\n",
    "    {\"eval_id\": 44, \"msg\": [{\"role\": \"user\", \"content\": \"같은 독감에 다시 걸리면 빨리 회복이 되더라구?\"}, {\"role\": \"assistant\", \"content\": \"네 맞습니다.\"}, {\"role\": \"user\", \"content\": \"그 이유가 뭐야?\"}]},\n",
    "    {\"eval_id\": 278, \"msg\": [{\"role\": \"user\", \"content\": \"노인들이 종종 후각 능력을 잃게 되는 경우가 있더라구?\"}, {\"role\": \"assistant\", \"content\": \"네 맞습니다.\"}, {\"role\": \"user\", \"content\": \"이렇게 냄새를 못맡게 되면 어떤 결과로 이어지지?\"}]},\n",
    "    {\"eval_id\": 53, \"msg\": [{\"role\": \"user\", \"content\": \"하늘이 파란 이유는?\"}]},\n",
    "    {\"eval_id\": 26, \"msg\": [{\"role\": \"user\", \"content\": \"짚신 벌레의 번식은 어떻게 이루어지나?\"}]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "<bos><start_of_turn>user\n",
      "\n",
      "    ## Instructions\n",
      "    - 당신은 사용자의 여러 대화 메시지를 하나의 검색 쿼리로 변환하는 전문가입니다.\n",
      "    - 아래 사용자의 대화에서 중요한 정보만 추출하여 간결하고 명확한 검색용 쿼리로 변환하세요.\n",
      "    - 대화 형식이 아닌, 연구나 조사를 위한 검색어처럼 정확한 질문을 생성하세요.\n",
      "\n",
      "    ## 대화\n",
      "    같은 독감에 다시 걸리면 빨리 회복이 되더라구?\n",
      "그 이유가 뭐야?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "독감 재감염 시 회복 기간 단축 관련 연구 논문\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<bos><start_of_turn>user\n",
      "\n",
      "    ## Instructions\n",
      "    - 당신은 사용자의 여러 대화 메시지를 하나의 검색 쿼리로 변환하는 전문가입니다.\n",
      "    - 아래 사용자의 대화에서 중요한 정보만 추출하여 간결하고 명확한 검색용 쿼리로 변환하세요.\n",
      "    - 대화 형식이 아닌, 연구나 조사를 위한 검색어처럼 정확한 질문을 생성하세요.\n",
      "\n",
      "    ## 대화\n",
      "    노인들이 종종 후각 능력을 잃게 되는 경우가 있더라구?\n",
      "이렇게 냄새를 못맡게 되면 어떤 결과로 이어지지?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "노인의 후각 감퇴, 원인 및 영향 분석\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<bos><start_of_turn>user\n",
      "\n",
      "    ## Instructions\n",
      "    - 당신은 사용자의 여러 대화 메시지를 하나의 검색 쿼리로 변환하는 전문가입니다.\n",
      "    - 아래 사용자의 대화에서 중요한 정보만 추출하여 간결하고 명확한 검색용 쿼리로 변환하세요.\n",
      "    - 대화 형식이 아닌, 연구나 조사를 위한 검색어처럼 정확한 질문을 생성하세요.\n",
      "\n",
      "    ## 대화\n",
      "    하늘이 파란 이유는?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "하늘이 파란색인 이유 설명\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<bos><start_of_turn>user\n",
      "\n",
      "    ## Instructions\n",
      "    - 당신은 사용자의 여러 대화 메시지를 하나의 검색 쿼리로 변환하는 전문가입니다.\n",
      "    - 아래 사용자의 대화에서 중요한 정보만 추출하여 간결하고 명확한 검색용 쿼리로 변환하세요.\n",
      "    - 대화 형식이 아닌, 연구나 조사를 위한 검색어처럼 정확한 질문을 생성하세요.\n",
      "\n",
      "    ## 대화\n",
      "    짚신 벌레의 번식은 어떻게 이루어지나?<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n",
      "짚신벌레 번식 과정 설명\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for test_queries in dummy_data:\n",
    "    search_query = generate_search_query(test_queries['msg'])\n",
    "    print(search_query)\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
